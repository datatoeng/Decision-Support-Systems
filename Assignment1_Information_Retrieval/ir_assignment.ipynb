{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "ir_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdkwQ36739Wi",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 2: IR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-gYMXKq39Wj",
        "colab_type": "text"
      },
      "source": [
        "## Preparations\n",
        "* Put all your imports, and path constants in the next cells\n",
        "* Make sure all your path constants are **relative to** ***DATA_DIR*** and **NOT hard-coded** in your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSxd1E73zdBw",
        "colab_type": "text"
      },
      "source": [
        "Student Name: Yuchao Wu\n",
        "Studnet Number: 1000651984"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSChF98s8ErB",
        "colab_type": "code",
        "outputId": "f717887c-d22b-4000-b119-0f96d2dc622a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "!pip install whoosh\n",
        "!pip install pytrec_eval\n",
        "!pip install wget"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting whoosh\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/19/24d0f1f454a2c1eb689ca28d2f178db81e5024f42d82729a4ff6771155cf/Whoosh-2.7.4-py2.py3-none-any.whl (468kB)\n",
            "\u001b[K     |████████████████████████████████| 471kB 2.9MB/s \n",
            "\u001b[?25hInstalling collected packages: whoosh\n",
            "Successfully installed whoosh-2.7.4\n",
            "Collecting pytrec_eval\n",
            "  Downloading https://files.pythonhosted.org/packages/36/0a/5809ba805e62c98f81e19d6007132712945c78e7612c11f61bac76a25ba3/pytrec_eval-0.4.tar.gz\n",
            "Building wheels for collected packages: pytrec-eval\n",
            "  Building wheel for pytrec-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytrec-eval: filename=pytrec_eval-0.4-cp36-cp36m-linux_x86_64.whl size=274549 sha256=9628bc9016a739b2f1c29bda0cfc0aa3ee64ed00b1169a7df03d067c65736010\n",
            "  Stored in directory: /root/.cache/pip/wheels/58/30/73/8858a1b6e5e2674e2ea85c9904949c06addcf6fd34d59b5ea6\n",
            "Successfully built pytrec-eval\n",
            "Installing collected packages: pytrec-eval\n",
            "Successfully installed pytrec-eval-0.4\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=dd706518632d692d7fc163c8739c06079e80322f330d32c061b96f2477d9b632\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HIF5uBV8cRy",
        "colab_type": "code",
        "outputId": "4f022ddc-573f-4982-d190-ec6cacf5a8b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import wget\n",
        "wget.download(\"https://github.com/MIE451-1513-2019/course-datasets/raw/master/government.zip\", \"government.zip\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'government.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN-TAsbPAsRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip government.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VNv24P839Wk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports\n",
        "# Put all your imports here\n",
        "from whoosh import index, writing\n",
        "from whoosh.fields import Schema, TEXT, KEYWORD, ID, STORED\n",
        "from whoosh.analysis import *\n",
        "from whoosh.qparser import QueryParser\n",
        "import os.path\n",
        "from pathlib import Path\n",
        "import tempfile\n",
        "import subprocess\n",
        "import pytrec_eval\n",
        "import wget\n",
        "from whoosh import scoring\n",
        "from whoosh import qparser"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CTt1NZr39Wo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR = \"government\"\n",
        "#\n",
        "# Put other path constants here\n",
        "#\n",
        "DOCUMENTS_DIR = os.path.join(DATA_DIR, \"documents\")\n",
        "TOPIC_FILE = os.path.join(DATA_DIR, \"gov.topics\")\n",
        "QRELS_FILE = os.path.join(DATA_DIR, \"gov.qrels\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1of-Wop39Ws",
        "colab_type": "text"
      },
      "source": [
        "## Question 1\n",
        "Provide your text answers in the following two markdown cells"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu_aozrL39Ws",
        "colab_type": "text"
      },
      "source": [
        "### Q1 (a): Provide answer to Q1 (a) here [markdown cell]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5EFcmkOz0Js",
        "colab_type": "text"
      },
      "source": [
        "Solution: MAP is considered as appropriate measure for the government web sites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVMD_vZn39Wt",
        "colab_type": "text"
      },
      "source": [
        "### Q1 (b): Provide answer to Q1 (b) here [markdown cell]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJkd1alst7bF",
        "colab_type": "text"
      },
      "source": [
        "Solution: The mean average precision measures the average precesion values at ranks of relevant documents. Bascially, it calculate average Precision across multiple queries or rankings. Its evluation considers the order of the documents. This is to say, a large MAP score indicates that there are many relevant docuemnts are ranked at the top of the retrieved results. This would in turn help users to find information they need easily and quickly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaebEQWj39Wt",
        "colab_type": "text"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLwEGzwz39Wu",
        "colab_type": "text"
      },
      "source": [
        "### Q2 (a): Write your code below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5ZkoByd39Wv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Put your code for creating the index here (you can add more cells).\n",
        "# Make sure you save the final index in the variable INDEX_Q2, your query parser in QP_Q2, and your searcher in SEARCHER_Q2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l4sMYtzQco6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Create Index function\n",
        "def createIndex(schema):\n",
        "    # Generate a temporary directory for the index\n",
        "    indexDir = tempfile.mkdtemp()\n",
        "    # create and return the index\n",
        "    return index.create_in(indexDir, schema)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8WUQOMRHtTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Schema for the index (The schema specifies the fields of documents in an index. Each doc can have multiple fileds: title, content, url,date)\n",
        "mySchema = Schema(file_path = ID(stored=True),\n",
        "                  file_content = TEXT(analyzer = RegexTokenizer()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zguxgsNTH0P8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the index at the path INDEX_DIR based on the new schema\n",
        "myIndex = createIndex(mySchema)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhlhNeiZIIlK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define a indexing file function\n",
        "# open each docuemnt and index each docuemnt\n",
        "def addFilesToIndex(indexObj, fileList):\n",
        "    # open writer\n",
        "    writer = writing.BufferedWriter(indexObj, period=None, limit=1000)\n",
        "\n",
        "    try:\n",
        "        # write each file to index\n",
        "        for docNum, filePath in enumerate(fileList):\n",
        "            with open(filePath, \"r\", encoding=\"utf-8\") as f:\n",
        "                fileContent = f.read()\n",
        "                writer.add_document(file_path = filePath,\n",
        "                                    file_content = fileContent)\n",
        "\n",
        "                # print status every 1000 documents\n",
        "                if (docNum+1) % 1000 == 0:\n",
        "                    print(\"already indexed:\", docNum+1)\n",
        "        print(\"done indexing.\")\n",
        "\n",
        "    finally:\n",
        "        # close the index\n",
        "        writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckAvYlnXR72l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a list of files to index\n",
        "filesToIndex = [str(filePath) for filePath in Path(DOCUMENTS_DIR).glob(\"**/*\") if filePath.is_file()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae40BzQXSGkz",
        "colab_type": "code",
        "outputId": "e2b3750a-cc80-42f0-8a97-72a601dd940d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "# count files to index\n",
        "print(\"number of files:\", len(filesToIndex))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of files: 4078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqhY6-6WRWfJ",
        "colab_type": "code",
        "outputId": "251149d2-cd36-4011-f32d-ba18cafa24e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "filesToIndex[0:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['government/documents/68/G00-68-3094820',\n",
              " 'government/documents/68/G00-68-0361254',\n",
              " 'government/documents/68/G00-68-2512403',\n",
              " 'government/documents/68/G00-68-0000000',\n",
              " 'government/documents/68/G00-68-1332243']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ4Y2YwTSZpw",
        "colab_type": "code",
        "outputId": "18bc6491-cbf9-4591-ff08-7d3294ba6a00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "# Finishing the indexing\n",
        "addFilesToIndex(myIndex, filesToIndex)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "already indexed: 1000\n",
            "already indexed: 2000\n",
            "already indexed: 3000\n",
            "already indexed: 4000\n",
            "done indexing.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-cCZ_BGIOKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a query parser for the field \"file_content\" in the index\n",
        "myQueryParser = QueryParser(\"file_content\", schema=myIndex.schema)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY-KXtXFRBBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a searcher\n",
        "mySearcher = myIndex.searcher()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibPPoKXF39Wx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INDEX_Q2 = myIndex # Replace None with your index for Q2\n",
        "QP_Q2 = myQueryParser # Replace None with your query parser for Q2\n",
        "SEARCHER_Q2 = mySearcher # Replace None with your searcher for Q2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6AcfHJfE0hP",
        "colab_type": "code",
        "outputId": "78f9c22b-6a49-4af6-eca9-b72587d3fdf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "# Inspect the index\n",
        "# Is it empty?\n",
        "print(\"Index is empty?\", INDEX_Q2.is_empty())\n",
        "\n",
        "# How many files indexed?\n",
        "print(\"Number of indexed files:\", INDEX_Q2.doc_count())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index is empty? False\n",
            "Number of indexed files: 4078\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns0mb3JpE0xS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a reader object on the index\n",
        "myReader = INDEX_Q2.reader()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKDtReNqE5DP",
        "colab_type": "code",
        "outputId": "e0cad1f0-bff4-48bb-86fc-ef55cb4bff8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "# Insepct the first 5 indexed documents\n",
        "[(docnum, doc_dict) for (docnum, doc_dict) in myReader.iter_docs()][0:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, {'file_path': 'government/documents/68/G00-68-3094820'}),\n",
              " (1, {'file_path': 'government/documents/68/G00-68-0361254'}),\n",
              " (2, {'file_path': 'government/documents/68/G00-68-2512403'}),\n",
              " (3, {'file_path': 'government/documents/68/G00-68-0000000'}),\n",
              " (4, {'file_path': 'government/documents/68/G00-68-1332243'})]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs-qgnks39Wz",
        "colab_type": "text"
      },
      "source": [
        "### Q2 (b): Provide answer to Q2 (b) here [markdown cell]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD_6RBxqRJBu",
        "colab_type": "text"
      },
      "source": [
        "Solution for Q2(b): As shown below, the map all has value of 0.1971."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qndlewLRSr5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define a Trec evulation function\n",
        "def pyTrecEval(topicFile, qrelsFile, queryParser, searcher):\n",
        "    # Load topic file - a list of topics(search phrases) used for evalutation\n",
        "    with open(topicFile, \"r\") as tf:\n",
        "        topics = tf.read().splitlines()\n",
        "\n",
        "    # create an output file to which we'll write our results\n",
        "    tempOutputFile = tempfile.mkstemp()[1]\n",
        "    with open(tempOutputFile, \"w\") as outputTRECFile:\n",
        "        # for each evaluated topic:\n",
        "        # build a query and record the results in the file in TREC_EVAL format\n",
        "        for topic in topics:\n",
        "            topic_id, topic_phrase = tuple(topic.split(\" \", 1))\n",
        "            #print(topic_id, topic_phrase)\n",
        "            topicQuery = queryParser.parse(topic_phrase)\n",
        "            topicResults = searcher.search(topicQuery, limit=None)\n",
        "            for (docnum, result) in enumerate(topicResults):\n",
        "                score = topicResults.score(docnum)\n",
        "                #print(\"%s Q0 %s %d %lf test\\n\" % (topic_id, os.path.basename(result[\"file_path\"]), docnum, score))\n",
        "                outputTRECFile.write(\"%s Q0 %s %d %lf test\\n\" % (topic_id, os.path.basename(result[\"file_path\"]), docnum, score))\n",
        "    with open(qrelsFile, 'r') as f_qrel:\n",
        "        qrel = pytrec_eval.parse_qrel(f_qrel)\n",
        "\n",
        "    with open(tempOutputFile, 'r') as f_run:\n",
        "        run = pytrec_eval.parse_run(f_run)\n",
        "\n",
        "    evaluator = pytrec_eval.RelevanceEvaluator(\n",
        "        qrel, pytrec_eval.supported_measures)\n",
        "\n",
        "    results = evaluator.evaluate(run)\n",
        "    def print_line(measure, scope, value):\n",
        "        print('{:25s}{:8s}{:.4f}'.format(measure, scope, value))\n",
        "\n",
        "    for query_id, query_measures in results.items():\n",
        "        for measure, value in query_measures.items():\n",
        "            if measure == \"runid\":\n",
        "              continue\n",
        "            print_line(measure, query_id, value)\n",
        "    for measure in query_measures.keys():\n",
        "        if measure == \"runid\":\n",
        "              continue\n",
        "        print_line(\n",
        "            measure,\n",
        "            'all',\n",
        "            pytrec_eval.compute_aggregated_measure(\n",
        "                measure,\n",
        "                [query_measures[measure]\n",
        "                 for query_measures in results.values()]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2Zo1CoqS6eU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run the above function to check the score for each measure\n",
        "pyTrecEval(TOPIC_FILE, QRELS_FILE,QP_Q2,SEARCHER_Q2) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t25OBHbwdOsl",
        "colab_type": "text"
      },
      "source": [
        "Solution for Q2(b): As shown on the above resutl, the map all has value of 0.1971."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TUIW6hV39Wz",
        "colab_type": "text"
      },
      "source": [
        "### Q2 (c): Provide answer to Q2(c) here [markdown cell]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQzBgKQZdXhd",
        "colab_type": "text"
      },
      "source": [
        "The topics it did well are: 24 (1.0),18(1.0),\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FivRMGvRjTP8",
        "colab_type": "text"
      },
      "source": [
        "The topics it did poorly are: 28 (score = 0),16(0.0),9(0.00),7(0.00),6(0.0),2(0.0),1(0.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_e8DZ3K39W0",
        "colab_type": "text"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD0gzOt239W1",
        "colab_type": "text"
      },
      "source": [
        "### Q3 (a): Provide answer to Q3 (a) here [markdown cell]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5MJ14p5HW5O",
        "colab_type": "text"
      },
      "source": [
        "**What do you think would improve Whoosh’s performance on this test collection, and why?** - Solution: As shwon from example 1 to 6, the analyzers are reqruied to be updated to improve the whooh's performace. As it cannot understand the words in different forms (e.g., prefixes), failed to remove stop words and punctuation. \n",
        "\n",
        "Search System Evualtion: Take query 14, as an example. The document G00-79-4144643 is treat as a False Postive as it is not really relevant to the query but show up at the highest ranking. On the other hand, G00-89-0000000 (for example) is an FN because it is relevant to our search but not shown up in the ranking."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYFtcAHSEPFU",
        "colab_type": "code",
        "outputId": "87f8f3d1-0a88-4ce1-a93e-9aadbc70cbda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "# Understand the topic file - quries\n",
        "with open(TOPIC_FILE, \"r\") as f:\n",
        "    print(f.read())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 mining gold silver coal\n",
            "2 juvenile delinquency\n",
            "4 wireless communications\n",
            "6 physical therapists\n",
            "7 cotton industry\n",
            "9 genealogy searches\n",
            "10 Physical Fitness\n",
            "14 Agricultural biotechnology\n",
            "16 Emergency and disaster preparedness assistance\n",
            "18 Shipwrecks\n",
            "19 Cybercrime, internet fraud, and cyber fraud\n",
            "22 Veteran's Benefits\n",
            "24 Air Bag Safety\n",
            "26 Nuclear power plants\n",
            "28 Early Childhood Education\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8z2IJsu1S0Q",
        "colab_type": "code",
        "outputId": "24de2af0-2836-49c7-9c2b-905533633711",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "# Example 1: Evaluate the originial anlayzer - General inspect\n",
        "tokenizer = RegexTokenizer()\n",
        "[token.text for token in tokenizer(\"I LOVE basketball, and football and all the sports.\")]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'LOVE', 'basketball', 'and', 'football', 'and', 'all', 'the', 'sports']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK_teGpVCTx6",
        "colab_type": "text"
      },
      "source": [
        "As shown in example 1, the regular expression analyzer in the current search system has very limited filtering capbility (e.g., can only extract the words and igonore the white space without filtering out the stop words). A few adjustments to analyzer are requred to improve the overal performace of Whoosh performance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhIBEtmbA6gt",
        "colab_type": "code",
        "outputId": "55f5aa76-04ac-4e24-beb4-6dcd21cced71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "# Example 2: # Evaluate the originial anlayzer - Capitalization (topic 1)\n",
        "print(\"# docs with 'mining'\", myReader.doc_frequency(\"file_content\", \"mining\"))\n",
        "print(\"# docs with 'Mining'\", myReader.doc_frequency(\"file_content\", \"Mining\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# docs with 'mining' 45\n",
            "# docs with 'Mining' 59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8io9GH-Cafz",
        "colab_type": "text"
      },
      "source": [
        "As shown in above example, the regular expression analyzer in the current research system are case sensitive (e.g, treat \"Ming\" and \"ming\" as two different words)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fWdjNQcBe8l",
        "colab_type": "code",
        "outputId": "f3eb57e7-907b-4217-85d3-abdd536f9d77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "# Example 3: # Evaluate the originial anlayzer - Stop words (and, then, a)\n",
        "print(\"# docs with 'and'\", myReader.doc_frequency(\"file_content\", \"and\"))\n",
        "print(\"# docs with 'the'\", myReader.doc_frequency(\"file_content\", \"the\"))\n",
        "print(\"# docs with 'a'\", myReader.doc_frequency(\"file_content\", \"a\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# docs with 'and' 3348\n",
            "# docs with 'the' 3355\n",
            "# docs with 'a' 2522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jypE3PxNC07a",
        "colab_type": "text"
      },
      "source": [
        "As shown in above example, the regular expression analyzer in the current research system cannot filter out the commmon stop words: and, the, a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xlRNzIdBXpM",
        "colab_type": "code",
        "outputId": "2d8d6225-3a6c-414d-a1ff-9d76261bfda7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "# Example 5: # Evaluate the originial anlayzer - prefixes (Topic 4)\n",
        "print(\"# docs with 'communications'\", myReader.doc_frequency(\"file_content\", \"communications\"))\n",
        "print(\"# docs with 'commun'\", myReader.doc_frequency(\"file_content\", \"commun\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# docs with 'communications' 102\n",
            "# docs with 'commun' 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yelNVqEJEkti",
        "colab_type": "text"
      },
      "source": [
        "As shown in above example, the regular expression analyzer in the current research system cannot analyze the words in different form (e.g., 'communications' has a prefix form of 'commun'). In the real world, it is very likely for the users to enter the short version of the words instead of the full words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL9Z-_IRFN_V",
        "colab_type": "code",
        "outputId": "335dcc53-4420-472e-a6d7-cec63644d057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "# Example 6: # Evaluate the originial anlayzer - punctuation (Topic 19)\n",
        "print(\"# docs with 'Cybercrime,'\", myReader.doc_frequency(\"file_content\", \"Cybercrime,\"))\n",
        "print(\"# docs with 'Cybercrime'\", myReader.doc_frequency(\"file_content\", \"Cybercrime\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# docs with 'Cybercrime,' 0\n",
            "# docs with 'Cybercrime' 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndy7_oE7G1Hw",
        "colab_type": "text"
      },
      "source": [
        "As shown in above example, the regular expression analyzer in the current research system failed to remove the punctuations (e.g., 'Cybercrime,' vs'Cybercrime' )."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZNOg00dJFlJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def printRelName(topicFile, qrelsFile, queryParser, searcher, id):\n",
        "  with open(topicFile, \"r\") as tf:\n",
        "        topics = tf.read().splitlines()\n",
        "  for topic in topics:\n",
        "        topic_id, topic_phrase = tuple(topic.split(\" \", 1))\n",
        "        if topic_id == id:\n",
        "          print(\"---------------------------Topic_id and Topic_phrase----------------------------------\")\n",
        "          print(topic_id, topic_phrase)\n",
        "          topicQuery = queryParser.parse(topic_phrase)\n",
        "          topicResults = searcher.search(topicQuery, limit=None)\n",
        "          print(\"---------------------------Return documents----------------------------------\")\n",
        "          for (docnum, result) in enumerate(topicResults):\n",
        "              score = topicResults.score(docnum)\n",
        "              print(\"%s Q0 %s %d %lf test\" % (topic_id, os.path.basename(result[\"file_path\"]), docnum, score))\n",
        "          print(\"---------------------------Relevant documents----------------------------------\")\n",
        "          with open(qrelsFile, 'r') as f_qrel:\n",
        "            qrels = f_qrel.readlines()\n",
        "            for i in qrels:\n",
        "              qid, _, doc, rel = i.rstrip().split(\" \")\n",
        "              if qid == id and rel == \"1\":\n",
        "                print(i.rstrip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWYoOcHcJFy6",
        "colab_type": "code",
        "outputId": "1d86aa22-8e47-4922-f8ed-db733131a21b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "# FP - Irrelevant documents ranked highly\n",
        "# FN - Relevant documents not ranked highly\n",
        "printRelName(TOPIC_FILE, QRELS_FILE, myQueryParser, mySearcher, \"14\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------Topic_id and Topic_phrase----------------------------------\n",
            "14 Agricultural biotechnology\n",
            "---------------------------Return documents----------------------------------\n",
            "14 Q0 G00-79-4144643 0 16.017277 test\n",
            "14 Q0 G00-09-1193469 1 15.942973 test\n",
            "14 Q0 G00-45-0809730 2 15.640293 test\n",
            "14 Q0 G00-89-0000000 3 15.377247 test\n",
            "14 Q0 G00-88-1894712 4 8.188481 test\n",
            "14 Q0 G00-34-0444524 5 3.239981 test\n",
            "14 Q0 G00-84-0274223 6 1.544029 test\n",
            "---------------------------Relevant documents----------------------------------\n",
            "14 0 G00-89-0000000 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFRgN9U14lDu",
        "colab_type": "text"
      },
      "source": [
        "The document G00-79-4144643 is treat as a false postive as it is not really relevant to the query but show up at the highest ranking. On the other hand, G00-89-0000000 is an FN because it is relevant to our search but not rank high in the ranking."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzwPVMgc39W1",
        "colab_type": "text"
      },
      "source": [
        "### Q3 (b): Write your code below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAef6qiu39W2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Put your code for creating the index here (you can add more cells).\n",
        "# Make sure you save the final index in the variable INDEX_Q3, your query parser in QP_Q3, and your searcher in SEARCHER_Q3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60NwCnDyHSF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.stem import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvFD0Pla3uEg",
        "colab_type": "code",
        "outputId": "2cc4c5da-234e-47e2-dff4-9947a2f6506e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "# download required resources\n",
        "nltk.download(\"wordnet\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSbVYklL6Fkw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we'll compare two stemmers and a lemmatizer\n",
        "lrStem = LancasterStemmer()\n",
        "sbStem = SnowballStemmer(\"english\")\n",
        "wnLemm = WordNetLemmatizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFvpSH7L_Onc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dont change this! Use it as-is in your code\n",
        "# This filter will run for both the index and the query\n",
        "from whoosh.analysis import Filter\n",
        "class CustomFilter(Filter):\n",
        "    is_morph = True\n",
        "    def __init__(self, filterFunc, *args, **kwargs):\n",
        "        self.customFilter = filterFunc\n",
        "        self.args = args\n",
        "        self.kwargs = kwargs\n",
        "    def __eq__(self):\n",
        "        return (other\n",
        "                and self.__class__ is other.__class__)\n",
        "    def __call__(self, tokens):\n",
        "        for t in tokens:\n",
        "            if t.mode == 'query': # if called by query parser\n",
        "                t.text = self.customFilter(t.text, *self.args, **self.kwargs)\n",
        "                yield t\n",
        "            else: # == 'index' if called by indexer\n",
        "                t.text = self.customFilter(t.text, *self.args, **self.kwargs)\n",
        "                yield t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWUOAqiOHNIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define a modified analyzer\n",
        "NewAnalyzer = RegexTokenizer() | LowercaseFilter() | IntraWordFilter() | StopFilter() | CustomFilter(LancasterStemmer().stem)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14RAV9HFGaBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a Schema with the new analyzer\n",
        "mySchema2 = Schema(file_path = ID(stored=True),\n",
        "                   file_content = TEXT(analyzer = NewAnalyzer))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eooZaXjvTryk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the index based on the new schema\n",
        "myIndex2 = createIndex(mySchema2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hem3Ws4GTv6U",
        "colab_type": "code",
        "outputId": "4b34d312-eeb2-4bb6-ef6f-e3e65c1ba459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "addFilesToIndex(myIndex2, filesToIndex)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "already indexed: 1000\n",
            "already indexed: 2000\n",
            "already indexed: 3000\n",
            "already indexed: 4000\n",
            "done indexing.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHEvJ6JdT1Gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "myQueryParser2 = QueryParser(\"file_content\", schema=myIndex2.schema)\n",
        "mySearcher2 = myIndex2.searcher()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H6yUwtd39W4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INDEX_Q3 = myIndex2 # Replace None with your index for Q3\n",
        "QP_Q3 = myQueryParser2  # Replace None with your query parser for Q3\n",
        "SEARCHER_Q3 = mySearcher2 # Replace None with your searcher for Q3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D-GgS62M3rZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pyTrecEval(TOPIC_FILE, QRELS_FILE, myQueryParser2, mySearcher2) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEyZPg_y2IZr",
        "colab_type": "text"
      },
      "source": [
        "**Solution:**  MAP_all = 0.3456 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgqPO8i4ZsKo",
        "colab_type": "code",
        "outputId": "7522f3aa-50c5-432c-eb52-2de3d6022f41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "# check the query from part a\n",
        "printRelName(TOPIC_FILE, QRELS_FILE, myQueryParser2, mySearcher2, \"14\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------------Topic_id and Topic_phrase----------------------------------\n",
            "14 Agricultural biotechnology\n",
            "---------------------------Return documents----------------------------------\n",
            "14 Q0 G00-89-0000000 0 18.326725 test\n",
            "14 Q0 G00-79-4144643 1 16.239838 test\n",
            "14 Q0 G00-97-1475424 2 15.661743 test\n",
            "14 Q0 G00-01-3251318 3 15.661743 test\n",
            "14 Q0 G00-51-1924264 4 15.457968 test\n",
            "14 Q0 G00-72-0385489 5 15.132446 test\n",
            "14 Q0 G00-86-2926152 6 14.131987 test\n",
            "14 Q0 G00-45-0809730 7 14.003708 test\n",
            "14 Q0 G00-09-1193469 8 13.867392 test\n",
            "14 Q0 G00-36-2788975 9 13.594618 test\n",
            "14 Q0 G00-97-2215955 10 13.402500 test\n",
            "14 Q0 G00-09-1404763 11 13.278104 test\n",
            "14 Q0 G00-10-2024294 12 13.127152 test\n",
            "14 Q0 G00-91-1609512 13 13.099502 test\n",
            "14 Q0 G00-06-2853218 14 12.474858 test\n",
            "14 Q0 G00-35-2527252 15 12.412342 test\n",
            "14 Q0 G00-06-0690672 16 12.165935 test\n",
            "14 Q0 G00-86-0847220 17 11.425662 test\n",
            "14 Q0 G00-88-1894712 18 11.319674 test\n",
            "14 Q0 G00-70-3424520 19 10.954989 test\n",
            "14 Q0 G00-07-2371962 20 9.207667 test\n",
            "14 Q0 G00-34-0444524 21 6.377703 test\n",
            "14 Q0 G00-21-4119651 22 5.548831 test\n",
            "14 Q0 G00-84-0274223 23 4.989805 test\n",
            "14 Q0 G00-82-3144058 24 2.014143 test\n",
            "14 Q0 G00-46-0840102 25 1.843624 test\n",
            "---------------------------Relevant documents----------------------------------\n",
            "14 0 G00-89-0000000 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_6p_7dlee0D",
        "colab_type": "text"
      },
      "source": [
        "As shown above the relevant docuemnt G00-89-0000000 has been placed on the first rankning in the modefied system, whereas it ranked at 4th in the rankings for part a)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD4nxtDK39W7",
        "colab_type": "text"
      },
      "source": [
        "### Q3 (c): Provide answer to Q3 (c) here [markdown cell]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KSxLTztU_Rb",
        "colab_type": "text"
      },
      "source": [
        "Additional filters were added to the current search system. For example, lowercaseFilter() was used to sense the words with lower cases. IntraWordFilter() was added to remove punctiona next to the words. Also, the StopFIlter() was added to remove the stop words. Finally, the NLTK stemmers were also added to the filter (e.g., landcaster stemmer). Overall, the MAP_all was improved from to 0.1971 to 0.3456 with the modifed analyzer.\n",
        "\n",
        "In addition, the relevant docuemnt G00-89-0000000 (topic 14), was ranked the first place after using the modifed analyzer while it did rank high in the old analyzer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cntL2Jdt39W8",
        "colab_type": "text"
      },
      "source": [
        "### Q3 (d): Provide answer to Q3 (d) here [markdown cell]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh6uqI5oWOZx",
        "colab_type": "text"
      },
      "source": [
        "YES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKhLuIOw39W8",
        "colab_type": "text"
      },
      "source": [
        "### Q3 (e): Provide answer to Q3 (e) here [markdown cell]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYGBGnZXWREN",
        "colab_type": "text"
      },
      "source": [
        "YES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl4AUf0n39W9",
        "colab_type": "text"
      },
      "source": [
        "### Q3 (f): Provide answer to Q3 (f) here [markdown cell]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96RcxYmtgDGc",
        "colab_type": "text"
      },
      "source": [
        "Overall, it is evient that the modifed analyzer plays a significnat role in improving the system's performance in terms of retriving the relevant docuemnt. The MAP_all was imrpoved from 0.1971 to 0.3456 when applying the new analyzers. Some query topic, such as #14, shows an siginificant improvement and retrives the relevant docuement for the user whereas the origincial system failed to retrive the appropriate docuemnt. However, the udpated system still need some improvements for a better information retrial purpose."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs6teq2k39W-",
        "colab_type": "text"
      },
      "source": [
        "## Question 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-ZpjRdN39XD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Put your code for creating the index here (you can add more cells).\n",
        "# Make sure you save the final index in the variable INDEX_Q4, your query parser in QP_Q4, and your searcher in SEARCHER_Q4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPjJXXa_vX_7",
        "colab_type": "text"
      },
      "source": [
        "### Please answer the following questions here\n",
        "(a) A clear list of all final modifications made.  \n",
        "(b)  Why each modification was made – how did it help?  \n",
        "(c)  The  final  MAP  performance  that  these  modifications  attained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUpaNMk_spwV",
        "colab_type": "text"
      },
      "source": [
        "(a) Several Key modificaitons are: 1) Modifed Analyzer with lowercase Filter, intraworFilter,stopfilter,lancasterStemmer. \n",
        "2) Updated Query Parser: repalce the \"or\" algrithm instead of \"AND\". \n",
        "3) Upadted Scoring system: implemented BM25F with B =0.75 and several trails for K1 values ranging from 1.2 to 2.0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_WDvkHWvv7y",
        "colab_type": "text"
      },
      "source": [
        "(b) For the analzyer, the above-mentioned filters could do the functons, such as treating the upper and lower cases as same words, removing stop words, and reconiging the base form of the words. The purpose of this is to help the user retrieve the relevant information when indexed text contains words in different form than the one the user searches for.\n",
        "The query with \"OR\" algrithm, instead of requiring all the terms present for a match, would only need any of the term present for a docuemnt to match. This would show more relevant and related results to the user.\n",
        "\n",
        "For the scoring system, tuning the different paramers in BM25F scoring method (e.g., B and K1) would optimize the score for the research system. For example, when the text is a lot longer or divese, the K1 value of BM25F is suggested to be larger, which would increase the cap of term frequence saturation. Therefore, the user could find the docuemnts more quickly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv7VJIqCH0AR",
        "colab_type": "text"
      },
      "source": [
        "(c) The final MAP is 0.4026 when B = 0.55, K1 =2.55."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaFsiDwknjwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define a modified analyzer\n",
        "NewAnalyzer = RegexTokenizer() | LowercaseFilter() | IntraWordFilter() | StopFilter() | CustomFilter(LancasterStemmer().stem)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDFz1evwoWnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a Schema with the new analyzer\n",
        "mySchemaQ4 = Schema(file_path = ID(stored=True),\n",
        "                   file_content = TEXT(analyzer = NewAnalyzer))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhIQY4uHofu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the index based on the new schema\n",
        "INDEXQ4 = createIndex(mySchemaQ4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "992d8dygol_r",
        "colab_type": "code",
        "outputId": "e2c38620-2408-422b-dbba-8232e31d41f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "addFilesToIndex(INDEXQ4, filesToIndex)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "already indexed: 1000\n",
            "already indexed: 2000\n",
            "already indexed: 3000\n",
            "already indexed: 4000\n",
            "done indexing.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsQS7Tw10GJz",
        "colab_type": "text"
      },
      "source": [
        "From the Whoosh guide, the defualt QUeryParser would search for all the terms by defualt. For example, the defualt parser treates the words as if they were connected by AND, which means that all the terms must be present for a docuemnt to match. Thus, we need to change the parser to use OR such that any of the terms may be present for a docuemnt to match. Reference: https://whoosh.readthedocs.io/en/latest/parsing.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D42nJ9oi_Ke7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define custimized Parser with OR instead of the default AND\n",
        "myQueryParser3 = QueryParser(\"file_content\", schema=INDEXQ4.schema,group=qparser.OrGroup)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeVcQeQ56Sqe",
        "colab_type": "text"
      },
      "source": [
        "For scoring system, the BM25F scoring will be used to improve the search performance. By defualt, the parameter of BM25F, b = 0.75 and k1 = 1.2, which would work well for the most of cases. For the purpose of the optimization, it would be worth tring some different values.\n",
        "\n",
        "\n",
        "\n",
        "Reference:https://www.elastic.co/blog/practical-bm25-part-3-considerations-for-picking-b-and-k1-in-elasticsearch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpua7b2NDiG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# B = 0.75, K1 =1.2\n",
        "mySearcher3_K1 = myIndex2.searcher(weighting = scoring.BM25F(B = 0.75, K1 =1.2))\n",
        "pyTrecEval(TOPIC_FILE, QRELS_FILE, myQueryParser3, mySearcher3_K1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueCTJKfyrCZN",
        "colab_type": "text"
      },
      "source": [
        "map                      all     0.3797"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeNjAW4KrYfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# B = 0.75, K1 =1.5\n",
        "mySearcher3_K2 = myIndex2.searcher(weighting = scoring.BM25F(B = 0.75, K1 =1.5))\n",
        "pyTrecEval(TOPIC_FILE, QRELS_FILE, myQueryParser3,mySearcher3_K2) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2KESEuPrv8-",
        "colab_type": "text"
      },
      "source": [
        "map_all = 0.3810 @ k1 = 1.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ4eDMi7riOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# B = 0.55, K1 =2.55\n",
        "mySearcher3_K3 = myIndex2.searcher(weighting = scoring.BM25F(B = 0.55, K1 =2.55))\n",
        "pyTrecEval(TOPIC_FILE, QRELS_FILE, myQueryParser3,mySearcher3_K3) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00sNGFUSr38F",
        "colab_type": "text"
      },
      "source": [
        "map_all = 0.4026 @ B = 0.55, K1 =2.55"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja1MLfC_39XG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# From above trails, we would store mySearcher3_K3 (k1 =2) as it has the highest score\n",
        "INDEX_Q4 = INDEXQ4 # Replace None with your index for Q4\n",
        "QP_Q4 = myQueryParser3 # Replace None with your query parser for Q4\n",
        "SEARCHER_Q4 = mySearcher3_K3 # Replace None with your searcher for Q4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxIckwJc39XL",
        "colab_type": "text"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8aamYn839XL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run the following cells to make sure your code returns the correct value types"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jniUiH1b39XO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from whoosh.index import FileIndex\n",
        "from whoosh.qparser import QueryParser\n",
        "from whoosh.searching import Searcher\n",
        "import os.path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3YfPSiI39XR",
        "colab_type": "text"
      },
      "source": [
        "### Q2 Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GCl6C7n39XS",
        "colab_type": "code",
        "outputId": "8bf81a19-4db9-4057-e936-14c8958f3224",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "assert(isinstance(INDEX_Q2, FileIndex)), \"Index Type\"\n",
        "assert(isinstance(QP_Q2, QueryParser)), \"Query Parser Type\"\n",
        "assert(isinstance(SEARCHER_Q2, Searcher)), \"Searcher Type\"\n",
        "print(\"Q2 Types Validated\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q2 Types Validated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9aZQ-PY39XW",
        "colab_type": "text"
      },
      "source": [
        "### Q3 Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEKvL0g-39XX",
        "colab_type": "code",
        "outputId": "62fec277-9155-410b-f6f2-8b1217bbf9af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "assert(isinstance(INDEX_Q3, FileIndex)), \"Index Type\"\n",
        "assert(isinstance(QP_Q3, QueryParser)), \"Query Parser Type\"\n",
        "assert(isinstance(SEARCHER_Q3, Searcher)), \"Searcher Type\"\n",
        "print(\"Q3 Types Validated\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q3 Types Validated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO5zjmDt39Xd",
        "colab_type": "text"
      },
      "source": [
        "### Q4 Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddGGFQMP39Xd",
        "colab_type": "code",
        "outputId": "be0d4e17-76e8-4191-dfe0-0141f1add6c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "source": [
        "assert(isinstance(INDEX_Q4, FileIndex)), \"Index Type\"\n",
        "assert(isinstance(QP_Q4, QueryParser)), \"Query Parser Type\"\n",
        "assert(isinstance(SEARCHER_Q4, Searcher)), \"Searcher Type\"\n",
        "print(\"Q4 Types Validated\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q4 Types Validated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGcGddmR39Xf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}